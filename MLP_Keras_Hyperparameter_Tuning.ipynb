{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals of this notebook:\n",
    "\n",
    "- How to use Keras models in scikit-learn.\n",
    "- How to use grid search in scikit-learn.\n",
    "- How to tune batch size and training epochs.\n",
    "- How to tune optimization algorithms.\n",
    "- How to tune learning rate and momentum.\n",
    "- How to tune network weight initialization.\n",
    "- How to tune activation functions.\n",
    "- How to tune dropout regularization.\n",
    "- How to tune the number of neurons in the hidden layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Keras with hyperparmeters \n",
    "Keras models can be used in scikit-learn by wrapping them with the KerasClassifier or KerasRegressor class.\n",
    "\n",
    "To use these wrappers you must define a function that creates and returns your Keras sequential model, then pass this function to the build_fn argument when constructing the KerasClassifier class.\n",
    "\n",
    "Grid search is a model hyperparameter optimization technique.\n",
    "\n",
    "In scikit-learn this technique is provided in the GridSearchCV class.\n",
    "\n",
    "The GridSearchCV process will then construct and evaluate one model for each combination of parameters. Cross validation is used to evaluate each individual model.\n",
    "\n",
    "Grid Search CV Parameters:\n",
    "\n",
    "1. **Batch Size and Epochs**: The batch size in iterative gradient descent is the number of patterns shown to the network before the weights are updated. The number of epochs is the number of times that the entire training dataset is shown to the network during training.\n",
    "\n",
    "2. **Optimizer**: tune the optimization algorithm used to train the network\n",
    "\n",
    "3. **Learning Rate**: Learning rate controls how much to update the weight at the end of each batch\n",
    "\n",
    "4. **Kernel Initializer**: network weight initialization\n",
    "\n",
    "5. **Neural Activation**: The activation function controls the non-linearity of individual neurons and when to fire.\n",
    "\n",
    "6. **Dropout**: Tuning the dropout rate for regularization in an effort to limit overfitting and improve the modelâ€™s ability to generalize.\n",
    "\n",
    "7. **No. of Neurons**: The number of neurons in a layer is an important parameter to tune. A larger network requires more training and at least the batch size and number of epochs should ideally be optimized with the number of neurons.\n",
    "\n",
    "Please refer to the following link for more details:\n",
    "https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cheru\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.671731 using {'clf__batch_size': 10, 'clf__dropout': 0.1, 'clf__epochs': 8, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'rmsprop'}\n",
      "-0.687682 (0.001470) with: {'clf__batch_size': 10, 'clf__dropout': 0.1, 'clf__epochs': 4, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'rmsprop'}\n",
      "-0.689391 (0.001503) with: {'clf__batch_size': 10, 'clf__dropout': 0.1, 'clf__epochs': 4, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'adam'}\n",
      "-0.685037 (0.002920) with: {'clf__batch_size': 10, 'clf__dropout': 0.1, 'clf__epochs': 4, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'rmsprop'}\n",
      "-0.690357 (0.001732) with: {'clf__batch_size': 10, 'clf__dropout': 0.1, 'clf__epochs': 4, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'adam'}\n",
      "-0.673675 (0.001437) with: {'clf__batch_size': 10, 'clf__dropout': 0.1, 'clf__epochs': 8, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'rmsprop'}\n",
      "-0.684147 (0.001498) with: {'clf__batch_size': 10, 'clf__dropout': 0.1, 'clf__epochs': 8, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'adam'}\n",
      "-0.671731 (0.002630) with: {'clf__batch_size': 10, 'clf__dropout': 0.1, 'clf__epochs': 8, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'rmsprop'}\n",
      "-0.680115 (0.008058) with: {'clf__batch_size': 10, 'clf__dropout': 0.1, 'clf__epochs': 8, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'adam'}\n",
      "-0.687235 (0.002519) with: {'clf__batch_size': 10, 'clf__dropout': 0.2, 'clf__epochs': 4, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'rmsprop'}\n",
      "-0.688927 (0.002280) with: {'clf__batch_size': 10, 'clf__dropout': 0.2, 'clf__epochs': 4, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'adam'}\n",
      "-0.683904 (0.003191) with: {'clf__batch_size': 10, 'clf__dropout': 0.2, 'clf__epochs': 4, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'rmsprop'}\n",
      "-0.688091 (0.002049) with: {'clf__batch_size': 10, 'clf__dropout': 0.2, 'clf__epochs': 4, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'adam'}\n",
      "-0.678240 (0.004763) with: {'clf__batch_size': 10, 'clf__dropout': 0.2, 'clf__epochs': 8, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'rmsprop'}\n",
      "-0.686608 (0.001237) with: {'clf__batch_size': 10, 'clf__dropout': 0.2, 'clf__epochs': 8, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'adam'}\n",
      "-0.673036 (0.004095) with: {'clf__batch_size': 10, 'clf__dropout': 0.2, 'clf__epochs': 8, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'rmsprop'}\n",
      "-0.680545 (0.006087) with: {'clf__batch_size': 10, 'clf__dropout': 0.2, 'clf__epochs': 8, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'adam'}\n",
      "-0.688502 (0.001235) with: {'clf__batch_size': 20, 'clf__dropout': 0.1, 'clf__epochs': 4, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'rmsprop'}\n",
      "-0.691350 (0.001306) with: {'clf__batch_size': 20, 'clf__dropout': 0.1, 'clf__epochs': 4, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'adam'}\n",
      "-0.688915 (0.002484) with: {'clf__batch_size': 20, 'clf__dropout': 0.1, 'clf__epochs': 4, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'rmsprop'}\n",
      "-0.691340 (0.003663) with: {'clf__batch_size': 20, 'clf__dropout': 0.1, 'clf__epochs': 4, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'adam'}\n",
      "-0.685541 (0.000821) with: {'clf__batch_size': 20, 'clf__dropout': 0.1, 'clf__epochs': 8, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'rmsprop'}\n",
      "-0.688985 (0.002125) with: {'clf__batch_size': 20, 'clf__dropout': 0.1, 'clf__epochs': 8, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'adam'}\n",
      "-0.682727 (0.003491) with: {'clf__batch_size': 20, 'clf__dropout': 0.1, 'clf__epochs': 8, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'rmsprop'}\n",
      "-0.685305 (0.001882) with: {'clf__batch_size': 20, 'clf__dropout': 0.1, 'clf__epochs': 8, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'adam'}\n",
      "-0.689034 (0.001750) with: {'clf__batch_size': 20, 'clf__dropout': 0.2, 'clf__epochs': 4, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'rmsprop'}\n",
      "-0.691771 (0.000923) with: {'clf__batch_size': 20, 'clf__dropout': 0.2, 'clf__epochs': 4, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'adam'}\n",
      "-0.686261 (0.000939) with: {'clf__batch_size': 20, 'clf__dropout': 0.2, 'clf__epochs': 4, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'rmsprop'}\n",
      "-0.693072 (0.004483) with: {'clf__batch_size': 20, 'clf__dropout': 0.2, 'clf__epochs': 4, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'adam'}\n",
      "-0.687884 (0.001934) with: {'clf__batch_size': 20, 'clf__dropout': 0.2, 'clf__epochs': 8, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'rmsprop'}\n",
      "-0.687689 (0.001185) with: {'clf__batch_size': 20, 'clf__dropout': 0.2, 'clf__epochs': 8, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'adam'}\n",
      "-0.685158 (0.000360) with: {'clf__batch_size': 20, 'clf__dropout': 0.2, 'clf__epochs': 8, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'rmsprop'}\n",
      "-0.684323 (0.001446) with: {'clf__batch_size': 20, 'clf__dropout': 0.2, 'clf__epochs': 8, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'adam'}\n",
      "-0.691619 (0.001038) with: {'clf__batch_size': 40, 'clf__dropout': 0.1, 'clf__epochs': 4, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'rmsprop'}\n",
      "-0.691806 (0.001561) with: {'clf__batch_size': 40, 'clf__dropout': 0.1, 'clf__epochs': 4, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'adam'}\n",
      "-0.689602 (0.003315) with: {'clf__batch_size': 40, 'clf__dropout': 0.1, 'clf__epochs': 4, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'rmsprop'}\n",
      "-0.689998 (0.000506) with: {'clf__batch_size': 40, 'clf__dropout': 0.1, 'clf__epochs': 4, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'adam'}\n",
      "-0.687737 (0.002210) with: {'clf__batch_size': 40, 'clf__dropout': 0.1, 'clf__epochs': 8, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'rmsprop'}\n",
      "-0.691741 (0.000263) with: {'clf__batch_size': 40, 'clf__dropout': 0.1, 'clf__epochs': 8, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'adam'}\n",
      "-0.690893 (0.003763) with: {'clf__batch_size': 40, 'clf__dropout': 0.1, 'clf__epochs': 8, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'rmsprop'}\n",
      "-0.686159 (0.000580) with: {'clf__batch_size': 40, 'clf__dropout': 0.1, 'clf__epochs': 8, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'adam'}\n",
      "-0.690212 (0.000765) with: {'clf__batch_size': 40, 'clf__dropout': 0.2, 'clf__epochs': 4, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'rmsprop'}\n",
      "-0.692420 (0.000974) with: {'clf__batch_size': 40, 'clf__dropout': 0.2, 'clf__epochs': 4, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'adam'}\n",
      "-0.686750 (0.000997) with: {'clf__batch_size': 40, 'clf__dropout': 0.2, 'clf__epochs': 4, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'rmsprop'}\n",
      "-0.691066 (0.002688) with: {'clf__batch_size': 40, 'clf__dropout': 0.2, 'clf__epochs': 4, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'adam'}\n",
      "-0.688514 (0.000396) with: {'clf__batch_size': 40, 'clf__dropout': 0.2, 'clf__epochs': 8, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'rmsprop'}\n",
      "-0.691583 (0.000798) with: {'clf__batch_size': 40, 'clf__dropout': 0.2, 'clf__epochs': 8, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'adam'}\n",
      "-0.688309 (0.001040) with: {'clf__batch_size': 40, 'clf__dropout': 0.2, 'clf__epochs': 8, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'rmsprop'}\n",
      "-0.690995 (0.006039) with: {'clf__batch_size': 40, 'clf__dropout': 0.2, 'clf__epochs': 8, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'adam'}\n",
      "-0.691059 (0.000687) with: {'clf__batch_size': 60, 'clf__dropout': 0.1, 'clf__epochs': 4, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'rmsprop'}\n",
      "-0.691602 (0.000935) with: {'clf__batch_size': 60, 'clf__dropout': 0.1, 'clf__epochs': 4, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'adam'}\n",
      "-0.690810 (0.002162) with: {'clf__batch_size': 60, 'clf__dropout': 0.1, 'clf__epochs': 4, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'rmsprop'}\n",
      "-0.691421 (0.002452) with: {'clf__batch_size': 60, 'clf__dropout': 0.1, 'clf__epochs': 4, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'adam'}\n",
      "-0.689674 (0.001291) with: {'clf__batch_size': 60, 'clf__dropout': 0.1, 'clf__epochs': 8, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'rmsprop'}\n",
      "-0.692685 (0.001077) with: {'clf__batch_size': 60, 'clf__dropout': 0.1, 'clf__epochs': 8, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'adam'}\n",
      "-0.690995 (0.003392) with: {'clf__batch_size': 60, 'clf__dropout': 0.1, 'clf__epochs': 8, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'rmsprop'}\n",
      "-0.692691 (0.001473) with: {'clf__batch_size': 60, 'clf__dropout': 0.1, 'clf__epochs': 8, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'adam'}\n",
      "-0.691844 (0.000509) with: {'clf__batch_size': 60, 'clf__dropout': 0.2, 'clf__epochs': 4, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'rmsprop'}\n",
      "-0.692434 (0.000476) with: {'clf__batch_size': 60, 'clf__dropout': 0.2, 'clf__epochs': 4, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'adam'}\n",
      "-0.693600 (0.002225) with: {'clf__batch_size': 60, 'clf__dropout': 0.2, 'clf__epochs': 4, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'rmsprop'}\n",
      "-0.693935 (0.001991) with: {'clf__batch_size': 60, 'clf__dropout': 0.2, 'clf__epochs': 4, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'adam'}\n",
      "-0.688361 (0.001887) with: {'clf__batch_size': 60, 'clf__dropout': 0.2, 'clf__epochs': 8, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'rmsprop'}\n",
      "-0.692509 (0.000733) with: {'clf__batch_size': 60, 'clf__dropout': 0.2, 'clf__epochs': 8, 'clf__kernel_initializer': 'uniform', 'clf__optimizer': 'adam'}\n",
      "-0.687104 (0.001284) with: {'clf__batch_size': 60, 'clf__dropout': 0.2, 'clf__epochs': 8, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'rmsprop'}\n",
      "-0.693937 (0.001368) with: {'clf__batch_size': 60, 'clf__dropout': 0.2, 'clf__epochs': 8, 'clf__kernel_initializer': 'normal', 'clf__optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_regression,make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "#Generate a random n-class classification problem.\n",
    "X, y = make_classification(n_samples=100,n_features=10,n_informative=2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# load your data\n",
    "#X_train,X_test,y_train,y_test = make_my_dataset()\n",
    "\n",
    "# create a function that returns a model, taking as parameters things you\n",
    "# want to verify using cross-valdiation and model selection\n",
    "def create_model(optimizer='adagrad',\n",
    "                 kernel_initializer='glorot_uniform', \n",
    "                 dropout=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10,activation='relu',kernel_initializer=kernel_initializer))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1,activation='sigmoid',kernel_initializer=kernel_initializer))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# wrap the model using the function we created\n",
    "clf = KerasRegressor(build_fn=create_model,verbose=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# create parameter grid with various hyperparameters\n",
    "# prefixed by model name: clf__\n",
    "#turn on/off the needed parameters\n",
    "param_grid = {\n",
    "    'clf__batch_size': [10, 20, 40, 60],\n",
    "    'clf__epochs':[4,8],\n",
    "    'clf__optimizer':['rmsprop','adam',],\n",
    "    #'clf__learn_rate' : [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "    'clf__kernel_initializer':['uniform','normal'],\n",
    "    #'clf__activation' : ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear'],\n",
    "    'clf__dropout':[0.1,0.2]\n",
    "    #'clf__neurons' : [1, 5, 10, 15, 20, 25, 30]     \n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess',scaler),\n",
    "    ('clf',clf)\n",
    "])\n",
    "\n",
    "grid = GridSearchCV(pipeline, cv=3, param_grid=param_grid)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
